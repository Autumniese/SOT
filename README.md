# SOT: The Self-Optimal-Transport Feature Transform

This repository provides the official PyTorch implementation and pretrained models for **SOT** (The **S**elf-**O**ptimal-**T**ransport), as described in the paper (paper_hyperlink).

![alt text](https://i.ibb.co/m8Nw7gx/SOT.png)

The Self-Optimal-Transport (SOT) feature transform is designed to upgrade the set of features of a data instance to facilitate downstream matching or grouping related tasks. 

The transformed set encodes a rich representation of high order relations between the instance features. Distances  between transformed features capture their **direct** original similarity and their **third party** 'agreement' regarding similarity to other features in the set. 

A particular min-cost-max-flow fractional matching problem, whose entropy regularized version can be approximated by an optimal transport (OT) optimization, results in our transductive transform which is efficient, differentiable, equivariant, parameterless and probabilistically interpretable.

## Few-shot classification results

| First Header  | Second Header |
| ------------- | ------------- |
| Content Cell  | Content Cell  |
| Content Cell  | Content Cell  |

## Running instructions

### PT-MAP-SOT<sub>p</sub>

<details><summary>Dataset </summary>
<p>

    <details><summary>Datasets </summary>
    <p>
    </p>
</p>
</details>

<details><summary>Running PT-MAP-SOT<sub>p</sub> </summary>
<p>

    insert inst

</p>
</details>

<details><summary>Running PT-MAP-SOT<sub>t</sub> </summary>
<p>

    insert inst

</p>
</details>

<details><summary>Pretrained Models </summary>
<p>

    insert inst

</p>
</details>

## Citation

<p>

#### If you find this repository useful in your research, please cite:

    insert cite

</p>

## Acknowledgment
